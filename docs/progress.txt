# Brazilian Market ETL Pipeline - Progress Tracker

## Project Status: Phase 1 Complete

## Completed (2025-02-08)

### Phase 1: Foundation
- [x] Project directory structure created
- [x] Git repository initialized with proper .gitignore
- [x] docker-compose.yml created with PostgreSQL, Airflow, and Dashboard services
- [x] Database initialization scripts created (01_create_schemas.sql, 02_create_raw_tables.sql, 03_create_analytics_tables.sql)
- [x] .env.example created with all required variables
- [x] requirements.txt with all Python dependencies
- [x] LICENSE file (MIT)

### Phase 2: Data Extraction
- [x] extract/config.py - Extraction configuration class
- [x] extract/utils.py - Rate limiting, retry logic, validation utilities
- [x] extract/stock_extractor.py - StockExtractor class for Yahoo Finance
- [x] extract/bcb_extractor.py - BCBExtractor class for BCB API
- [x] load/db_loader.py - Database connection and loading utilities

### Phase 3: Data Transformation (dbt)
- [x] dbt_project.yml - Project configuration
- [x] profiles.yml - Database connection profiles
- [x] packages.yml - dbt dependencies
- [x] models/staging/_sources.yml - Source definitions
- [x] models/staging/_staging.yml - Model documentation
- [x] models/staging/stg_stocks.sql - Staging model for stocks
- [x] models/staging/stg_indicators.sql - Staging model for indicators
- [x] models/intermediate/_intermediate.yml - Model documentation
- [x] models/intermediate/int_stock_returns.sql - Return calculations
- [x] models/intermediate/int_stock_volatility.sql - Volatility calculations
- [x] models/intermediate/int_market_indicators.sql - Indicator pivot
- [x] models/marts/_marts.yml - Model documentation
- [x] models/marts/dim_date.sql - Date dimension
- [x] models/marts/dim_stock.sql - Stock dimension
- [x] models/marts/dim_indicator.sql - Indicator dimension
- [x] models/marts/fact_daily_market.sql - Fact table
- [x] macros/calculate_return.sql - Reusable return calculation
- [x] macros/generate_schema_name.sql - Schema name override
- [x] macros/test_positive_value.sql - Custom positive value test
- [x] tests/assert_no_future_dates.sql - Data quality test
- [x] tests/assert_positive_prices.sql - Data quality test
- [x] tests/assert_valid_returns.sql - Data quality test
- [x] seeds/stock_metadata.csv - Stock reference data

### Phase 4: Orchestration (Airflow)
- [x] airflow/dags/daily_market_etl.py - Daily incremental DAG
- [x] airflow/dags/backfill_historical.py - Historical backfill DAG

### Phase 5: Visualization (Streamlit Dashboard)
- [x] dashboard/app.py - Main dashboard entry point
- [x] dashboard/config.py - Dashboard configuration
- [x] dashboard/components/__init__.py - Components package
- [x] dashboard/components/charts.py - Reusable chart components
- [x] dashboard/components/queries.py - SQL queries for dashboard
- [x] dashboard/pages/1_Market_Overview.py - Market overview page
- [x] dashboard/pages/2_Sector_Analysis.py - Sector analysis page
- [x] dashboard/pages/3_Macro_Correlation.py - Macro correlation page
- [x] dashboard/pages/4_Stock_Screener.py - Stock screener page

### Phase 6: Testing
- [x] tests/__init__.py - Test package
- [x] tests/conftest.py - Pytest fixtures
- [x] tests/test_stock_extractor.py - StockExtractor tests
- [x] tests/test_bcb_extractor.py - BCBExtractor tests
- [x] tests/test_db_loader.py - DatabaseLoader tests

### Utilities
- [x] Dockerfile.dashboard - Dashboard container (gcc removed, no unused COPY)
- [x] Dockerfile.airflow - Airflow container (unused COPY requirements.txt removed)
- [x] .dockerignore - Excludes venv, logs, tests, docs, .git from build context
- [x] dashboard/.streamlit/config.toml - Streamlit server config (maxMessageSize=500)
- [x] scripts/setup_db.sh - Database setup script
- [x] scripts/start_project.sh - Start all Docker services (logs to logs/ dir)
- [x] scripts/close_project.sh - Stop all Docker services (logs to logs/ dir)
- [x] scripts/backfill_data.py - Data backfill script
- [x] scripts/validate_data.py - Data validation script

## Completed (2026-02-10)

### Docker Build Optimization
- [x] Created .dockerignore (context: ~811 MB → <1 MB)
- [x] Removed unused COPY requirements.txt from Dockerfile.dashboard and Dockerfile.airflow
- [x] Removed gcc from Dockerfile.dashboard (all packages use binary wheels)
- [x] Deleted __pycache__/ from dashboard/
- [x] Added comments to both Dockerfiles explaining design decisions
- [x] Updated all documentation (README, architecture.md, setup_guide.md, progress.txt)

### Streamlit Configuration
- [x] Created dashboard/.streamlit/config.toml with maxMessageSize=500

### Script Fixes
- [x] Fixed start_project.sh and close_project.sh to write logs to logs/ dir

### Airflow Configuration
- [x] Added AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: America/Sao_Paulo to docker-compose.yml

### Documentation Fixes
- [x] Fixed setup_guide.md: wrong --profile dashboard command (dashboard has no profile)
- [x] Updated README.md project structure: added .dockerignore, .streamlit/config.toml, 5_Historical_Analysis.py
- [x] Added "Docker Build Optimization" section to architecture.md
- [x] Updated can_be_removed.md to reflect all items implemented

### Bug Fix: Airflow DAG dbt tasks failing — "dbt: command not found"
- [x] Root cause: daily_market_etl.py runs dbt via BashOperator inside the Airflow
  container, but dbt was only installed in the separate dbt_runner container.
- [x] Fix: Added dbt-core==1.7.4 and dbt-postgres==1.7.4 to Dockerfile.airflow
- [x] Fix: Added DBT_PROFILES_DIR env var to airflow-scheduler in docker-compose.yml
  so dbt finds profiles.yml in /opt/airflow/dbt_project
- Requires: Airflow image rebuild

### Bug Fix: Streamlit maxMessageSize still exceeded on Comparative Performance
- [x] Increased limit from 500 MB to 2000 MB in dashboard/.streamlit/config.toml

### Bug Fix: Airflow dbt tasks failing — PermissionError on dbt.log
- [x] Root cause: dbt_project/logs/dbt.log is owned by root (created by the
  dbt_runner container). Previously the Airflow scheduler ran as UID 50000;
  now all containers run as the host user's UID via docker-compose user: directive.
- [x] Fix: Added --log-path /tmp/dbt_logs to all dbt BashOperator commands in
  both daily_market_etl.py and backfill_historical.py. dbt now writes its logs
  to /tmp inside the container where the airflow user has write access.

### Bug Fix: Streamlit dashboard extremely slow (~45s per stream)
- [x] Root cause A — Cartesian join in get_comparative_performance():
  The base_prices CTE returned one row per trading day per ticker (all with
  the same base_price via FIRST_VALUE). Joining back on ticker only produced
  a massive cross-product (4 tickers × 1250 days × 1250 = 6.25M rows instead
  of 5,000). Fixed by adding DISTINCT ON (s.stock_id) to the CTE and joining
  on stock_id instead of ticker.
- [x] Root cause B — No query caching:
  The Historical Analysis page runs 11+ heavy SQL queries on every Streamlit
  rerun (every widget interaction re-executes the full page). Added
  @st.cache_data(ttl=300, hash_funcs={Engine: id}) to all query functions in
  dashboard/components/queries.py. Results are now cached for 5 minutes,
  eliminating redundant database hits during interactive use.

## Pending Rebuild
- Dashboard image needs rebuild (queries.py changed): docker compose build dashboard
- Airflow image needs rebuild (Dockerfile.airflow changed): docker compose build airflow-init
- Then restart all: docker compose up -d

## Notes
- All core components implemented
- README.md exists with full documentation
- Airflow UI timezone set to America/Sao_Paulo via docker-compose.yml env var
- The dbt_run and dbt_test tasks showed "upstream_failed" because dbt_deps failed
  first with "dbt: command not found" — fixed by installing dbt in Airflow image
- dbt log permission issue fixed by redirecting logs to /tmp inside the container
- Dashboard query caching benefits all pages, not just Historical Analysis
